## Welcome
---

Hello, on my GitHub you can find some of the projects I have worked on.



* **NLP** | [**Sentiment analysis on large-scale vaccine-related tweets using PySpark**](https://github.com/rotembaruch/twitter-bot-detection). 
<br>Collecting by Twitter API V2 about 700K tweets with academic research access during the second year of COVID-19. Projecs includes text cleaning and employing the TextBlob tool for semantic valuing. Used PySpark and GCP.

* **E-commerce** | [**Product recommendation system using word2vec embedding**](https://github.com/rotembaruch/Product-Recommendation-System). 
<br>Conducting a word2vec embedding algorithm on sequential purchased items, which aims to learn the semantic relationships between the items. By extracting the probability vector from a trained logistic regression model, the system offers the customer three to five relevant items.

* **NLP** | [**Offensive comments classification using Bert**](https://github.com/rotembar22/Offensive-comments-classification-using-Bert). 
<br>Training Bert word embedding model for text classification. Project includes data preprocessing, model fine-tuning, and model evaluation.

___________________________________________________________________________________________________________________________________________________

The following projects were conducted in joint work as part of courses within my  MS Intelligent Systems studies. They will contain a paper and code implementation.

* **Deep Learning** | [**Semi-supervised anomaly detection by variational-autoencoder (VAE)**](https://github.com/rotembaruch/Semi-Supervised-Anomaly-Detection-by-Variational-Autoencoder-). 
<br>Training a VAE model with only "normal" instances, creating a "normal model". Performing hyperparameter tuning with a validation set on the VAE reconstruction error, which measures how test instances are "far" from the "normal mode".

* **NLP** |  [**Topic modeling**](https://github.com/rotembaruch/Gibbs-And-NMF-For-Topic-Modeling) 
<br>Topic modeling is an unsupervised machine learning for clustering word groups and similar expressions that best characterize a set of documents. In this study, we examined two different topic modeling algorithms, Gibbs and Non-negative Matrix Factorization (NMF). To test the models, we performed several experiments on two well-known datasets with different structures, and for evaluating the performance, we used a coherence score.

* **Computer Vision** |  [**Self-Attention layers in deep Convolutional Generative Adversarial Networks (GAN)**](https://github.com/rotembaruch/Self--Attention-Layers-in-Deep-Convolutional-Generative-Adversarial-Networks). 
<br>Comparing GAN models with and without self-attention layers, which intend to add a dimension of memory to the model for generating images with better spatial significance. The measurement tool we used to measure the generated image quality is FID.




### To Connect
---

 [<img src="https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white" />](https://www.linkedin.com/in/rotembar-ai/)

